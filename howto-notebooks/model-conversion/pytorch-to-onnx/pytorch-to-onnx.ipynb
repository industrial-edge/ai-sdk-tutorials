{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "SPDX-FileCopyrightText": "Copyright (C) Siemens AG 2021. All Rights Reserved.",
		    "SPDX-License-Identifier": "MIT"
      },
      "source": [
        "# Model conversion for PyTorch models\n",
        "\n",
        "This tutorial explains how to convert a PyTorch Model to a standardized ONNX format, which enables you to run your model on a GPU enabled AI Inference Server.  \n",
        "\n",
        "In this tutorial you will learn how to \n",
        "- load a model in 'pth' format\n",
        "- convert and save the loaded model into 'onnx' format\n",
        "- verify the input and output shape of the model\n",
        "\n",
        "For more information about the conversion and common pitfalls please refer to the official [PyTorch to ONNX exporter documentation](https://pytorch.org/docs/stable/onnx_torchscript.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Configure model path and input size. `MODEL_PATH` is the path of the PyTorch model you want to convert to ONNX format. The converted model will be saved to `ONNX_PATH`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "MODEL_PATH = os.path.join(\"models\", \"model.pth\")\n",
        "ONNX_PATH = os.path.join(\"output\", \"model.onnx\")\n",
        "\n",
        "IMAGE_WIDTH = 224\n",
        "IMAGE_HEIGHT = 224\n",
        "PIXEL_DEPTH = 3\n",
        "\n",
        "BATCH_SIZE = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if we have a GPU available, if so, define the map location accordingly, otherwise, we will be using CPU to run our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "if DEVICE == \"cuda\":\n",
        "\tmap_location = lambda storage, loc: storage.cuda()\n",
        "else:\n",
        "\tmap_location = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the PyTorch model\n",
        "\n",
        "This model is an image classification model based on a pretrained ResNet50 model. It was retrained with the `simatic_photos` dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch_model = torch.load(MODEL_PATH, map_location=map_location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move the model to the device and set it in evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch_model.to(DEVICE)\n",
        "torch_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert to ONNX\n",
        "\n",
        "PyTorch requires a random input for the conversion. The input size must be known beforehand.<br/>\n",
        "Use the `input_names` and `output_names` arguments to specify the input / output variable names used in the inference pipeline.<br/>\n",
        "Parameter `opset` defines the version of the `ONNX format`, opset version `13` refers to ONNX format `1.8.0` which is supported by AI Inference Server at the time of writing.\n",
        "\n",
        "> ⚠️ Warning<br/>\n",
        "> The `verbose` parameter must be set to `False`, otherwise the ONNX exporter can get stuck in an infinite loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch_input = torch.randn(BATCH_SIZE, PIXEL_DEPTH, IMAGE_WIDTH, IMAGE_HEIGHT, requires_grad=True, device=DEVICE)\n",
        "\n",
        "input_names = [ \"input_1\" ] \n",
        "output_names = [ \"output_1\" ]\n",
        "\n",
        "torch.onnx.export(\n",
        "    torch_model, \n",
        "    torch_input, \n",
        "    ONNX_PATH, \n",
        "    verbose=False, # Must be set to False\n",
        "    input_names=input_names, \n",
        "    output_names=output_names,\n",
        "    opset_version=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the ONNX model and validate it\n",
        "\n",
        "Check the consistency of a model with `onnx.checker.check_model`. An exception is raised if the test fails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(ONNX_PATH)\n",
        "onnx.checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input and Output shape\n",
        "\n",
        "Let's inspect how the model and its inputs and outputs are shaped.\n",
        "`graph.input` displays the input shape of the converted ONNX model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "onnx_model.graph.input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, the shape of the input is `[1 x 3 x 224 x 224]`.<br/>\n",
        "The shape of the output is `[1 x 5]`, which can be displayed with the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "onnx_model.graph.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executing the model\n",
        "\n",
        "Before packaging the model, it is recommended to try it out with the `onnxruntime` Python package.  \n",
        "To do so we need to provide  \n",
        "- an `onnxruntime.InferenceSession` with the preloaded model  \n",
        "- the dictionary of the `input` arrays with the expected shape and type.  \n",
        "  To test the model we are generating a numpy array with randomized float values. \n",
        "- the list of the `output` arrays.\n",
        "\n",
        "\n",
        "The `result` variable contains the output tensors in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "from onnxruntime import InferenceSession\n",
        "\n",
        "images = numpy.random.random((BATCH_SIZE, PIXEL_DEPTH, IMAGE_WIDTH, IMAGE_HEIGHT)).astype('float32')\n",
        "session = InferenceSession(ONNX_PATH)\n",
        "\n",
        "result = session.run([\"output_1\"], {\"input_1\": images})\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage of the ONNX model\n",
        "\n",
        "The AI Inference Server with GPU support accepts ONNX models for execution.  \n",
        "For this purpose the model must be packaged into a `GPURuntimeComponent` step using AI Software Development Kit.  \n",
        "For details on how to create `GPURuntimeComponent` and build pipelines that run on a GPU enabled AI Inference Server you can study the [Object Detection](\"../../use-cases/object-detection/Readme.md\") example."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "image_classification",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
