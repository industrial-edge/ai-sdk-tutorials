{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "SPDX-FileCopyrightText": "Copyright (C) Siemens AG 2021. All Rights Reserved.",
    		"SPDX-License-Identifier": "MIT"
      },
      "source": [
        "# Create the inference wrappers\n",
        "\n",
        "The notebook explains the role of Pre- and Postprocessing steps in the Pipeline in the aspect of GPURuntimeComponent.  \n",
        "The final Python code is already created and provided in files [preprocessing.py](../src/preprocessing/preprocessing.py) and [postprocessing.py](../src/postprocessing/postprocessing.py), so the Pipeline can be created without executing this notebook.  \n",
        "This case you can continue with building the Pipeline in notebook [30-CreatePipeline.ipynb](30-CreatePipeline.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating Preprocessing Step\n",
        "\n",
        "The responsibility of the `Preprocessing` PythonComponent is to receive `ImageSet` payload and transform it to the input required by the `GPURuntimeComponent`.  \n",
        "To do so, we need to be familiar with the `ImageSet` payload format. First, we need a picture to create this type of payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy\n",
        "from pathlib import Path\n",
        "\n",
        "image_dir = Path('../data/processed')\n",
        "\n",
        "images = list(str(f) for f in image_dir.rglob(\"*.jpg\"))\n",
        "images_count = len(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "image = cv2.imread(images[0])  # BGR image 224x224x3\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB image 224x224x3\n",
        "\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create ImageSet payload format\n",
        "\n",
        "The method defined below creates the required format, and will be put into the payload with name `vision_payload` which will be provided by the `AI Inference Server` when an image is arrived from the selected camera through `Vision Connector Application`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def image_to_bayer(image_path):\n",
        "    im = cv2.imread(image_path)  # RGB image 224x224x3\n",
        "    (height, width) = im.shape[:2]\n",
        "    (R,G,B) = cv2.split(im)\n",
        "\n",
        "    bayerrg8 = numpy.zeros((height, width), numpy.uint8)\n",
        "\n",
        "    # strided slicing for this pattern:\n",
        "    #   R G\n",
        "    #   G R\n",
        "    bayerrg8[0::2, 0::2] = R[0::2, 1::2] # top left\n",
        "    bayerrg8[0::2, 1::2] = G[0::2, 0::2] # top right\n",
        "    bayerrg8[1::2, 0::2] = G[1::2, 1::2] # bottom left\n",
        "    bayerrg8[1::2, 1::2] = B[1::2, 0::2] # bottom right\n",
        "\n",
        "    return bayerrg8, width, height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import datetime\n",
        "import json\n",
        "\n",
        "def create_imageset_dict(image_path):\n",
        "    timestamp = datetime.datetime.now()\n",
        "    \n",
        "    image_bytes, width, height = image_to_bayer(image_path)\n",
        "\n",
        "    return {\n",
        "        \"version\": \"1\",  # version of the Metadata format\n",
        "        \"count\": 1,  # Number of images on message\n",
        "        \"timestamp\": timestamp.isoformat(),  # Camera acquisition time\n",
        "        \"detail\": [{  # list of images with detailed information\n",
        "            \"id\": str(image_path),  # unique image identifier. this case we use the filename of the original image\n",
        "            \"timestamp\": str(timestamp.timestamp()),  # Timestamp provided by the camera\n",
        "            \"width\": width,  # image width\n",
        "            \"height\": height,  # image height\n",
        "            \"format\": \"BayerRG8\",  # image format configure\n",
        "            \"metadata\": \"\",  # optional extra information on image\n",
        "            \"image\": image_bytes  # image binary with the given 'format'\n",
        "        }]\n",
        "    }\n",
        "\n",
        "image_set_payload = {\"vision_payload\": create_imageset_dict(images[0])}\n",
        "image_set_payload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract image from ImageSet\n",
        "\n",
        "Now the task of the PythonComponent `Preprocessing` is to extract image data from the payload, and create a flat array of float32 data.  \n",
        "This time the original image is packaged into the payload in `BayerRG8` format, so the Preprocessing component converts it to a one-dimensional float32 array with using PIL Image and numpy transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "WIDTH = 224\n",
        "HEIGHT = 224\n",
        "\n",
        "extracted = image_set_payload['vision_payload']\n",
        "image_detail = extracted[\"detail\"][0]\n",
        "\n",
        "iuid = image_detail['id']\n",
        "width = image_detail.get(\"width\", WIDTH)\n",
        "height = image_detail.get(\"height\", HEIGHT)\n",
        "\n",
        "image_data = numpy.frombuffer(image_detail['image'], dtype=numpy.uint8)  # BayerRG8, (width x height, )\n",
        "print(image_data.shape)\n",
        "image_data = image_data.reshape(width, height)                           # BayerRG8, (width, height)\n",
        "print(image_data.shape)\n",
        "image_data = cv2.cvtColor(image_data, cv2.COLOR_BayerRG2RGB)             # RGB, (width, height, 3)\n",
        "print(image_data.shape)\n",
        "\n",
        "image_array = image_data.astype(numpy.float32) / 255.  # normalizing into [0,1) range and converting to float32\n",
        "\n",
        "print(f\"image_array shape: {image_array.shape}\")  # checking the image dimensions\n",
        "plt.imshow(image_array)  # showing the image\n",
        "plt.axis('off')\n",
        "\n",
        "image_array = image_array.transpose(2,0,1)  # changing the shape from (224, 224, 3) to (3, 224, 224) as expected by the model\n",
        "inputs = numpy.array(image_array.ravel())  # flattening the 3 dimensional array and adding to an empty batch\n",
        "print(f\"inputs shape {inputs.shape} and type '{inputs.dtype}'\")  # checking the input shape and type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the tensor is created, we can create the response `output` from `input` (in the aspect of GPURuntimeComponent) and `iuid` to connect the images later in the `Postprocessing` step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = {\n",
        "    'iuid': iuid,\n",
        "    'input': inputs\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inferencing the model\n",
        "\n",
        "To see the output of the model, let's inference the model to the created payload.  \n",
        "First, we load the model into an InferenceSession and then executes the model against the created `inputs`, as it happens in `AI Inference Server`.  \n",
        "More precisely, the `GPU Runtime` in `AI Inference Server` will reshape the one-dimensional `inputs` array, so we should do the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from onnxruntime import InferenceSession\n",
        "session = InferenceSession(\"../src/detection/1/model.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "boxes, labels, scores = session.run([\"boxes\",\"labels\",\"scores\"], {\"input\": inputs.reshape((1,3,224,224))})\n",
        "boxes, labels, scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Postprocessing component\n",
        "\n",
        "The responsibility of the `Postprocessing Python Component` is to receive the predictions from the `Detection GPU Runtime Component` and make a decision based on the results.  \n",
        "In the previous step we created the output of the model, now let's transform it to the payload format as the AI Inference Server would pass it to the Postprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "payload = {\n",
        "    \"iuid\": str(images[0]),\n",
        "    \"boxes\": boxes,\n",
        "    \"labels\": labels,\n",
        "    \"scores\": scores\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can form a judgment on the given predictions, now we are using a simple decision; if there is any scratches, or the number of the found holes is not 8, the board is wrong, other way it is ok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iuid = payload.get(\"iuid\", None)\n",
        "image_input = payload.get(\"input\", None)\n",
        "boxes = payload.get(\"boxes\", None)\n",
        "labels = payload.get(\"labels\", None)\n",
        "scores = payload.get(\"scores\", None)\n",
        "\n",
        "holes = 0\n",
        "scratches = 0\n",
        "for i in range(len(scores)):\n",
        "    if scores[i] > 0.8:\n",
        "        if labels[i] == 1:\n",
        "            holes += 1\n",
        "        if labels[i] == 2:\n",
        "            scratches +=1\n",
        "\n",
        "print(f\"The board contains {holes} holes and {scratches} scratches.\")\n",
        "prediction = \"OK\" if holes == 8 and scratches == 0 else \"DAMAGED\"\n",
        "\n",
        "response = {\n",
        "    \"prediction\": prediction,\n",
        "    \"result\": json.dumps({\n",
        "            \"prediction\": prediction,\n",
        "            \"holes\": holes,\n",
        "            \"scratces\": scratches,\n",
        "            \"message\": f\"The board with id '{iuid}' contains {holes} holes and {scratches} scratches.\"\n",
        "        })\n",
        "}\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the workflows are implemented and saved, you are ready to create the Pipeline in notebook [30-CreatePipeline.ipynb](./30-CreatePipeline.ipynb).  \n",
        "The code snippets above are saved in Python scripts as\n",
        "- [preprocessing.py](../src/preprocessing/preprocessing.py) and\n",
        "- [postprocessing.py](../src/postprocessing/postprocessing.py)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "(Python) Object Detection",
      "language": "python",
      "name": "object_detection"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}