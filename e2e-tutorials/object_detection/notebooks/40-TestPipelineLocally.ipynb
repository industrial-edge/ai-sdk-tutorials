{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "SPDX-FileCopyrightText": "Copyright (C) Siemens AG 2021. All Rights Reserved.",
    "SPDX-License-Identifier": "MIT"
   },
   "source": [
    "# Test the edge configuration package locally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces you how to execute a created Pipeline in your local Python environment.  \n",
    "During its execution, an `ImageSet` payload is created from images, as we discussed in the notebook [20-PreAndPostProcessing.ipynb](./20-PreAndPostProcessing.ipynb) and uses the Pipeline we created in notebook [30-CreatePipeline.ipynb](./30-CreatePipeline.ipynb).\n",
    "\n",
    "The main goal to understand \n",
    "- how the test inputs are formed, \n",
    "- how the PythonComponent test environment is created\n",
    "- how the GPURuntimeComponent test environment is created\n",
    "- how to check the Pipeline behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ImageSet input from a JPEG or PNG file\n",
    "\n",
    "As we discussed in notebook [](./20-PreAndPostProcessing.ipynb), the payload of the Pipeline is an `ImageSet` in a dictionary, which will be processed by the Preprocessing step. For this reason, we create this payload from images in folder _../src/data/processed_ with the help of method defined in notebook [10-ObjectDetectionModel.ipynb](./10-ObjectDetectionModel.ipynb) and saved into Python script [payload.py](../src/preprocessing/payload.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from preprocessing.payload import create_imageset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the required input format from an input JPG file using the method _create_imageset_dict_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/processed/\")\n",
    "files = list(str(f) for f in data_path.rglob(\"*.jpg\"))\n",
    "\n",
    "pipeline_inputs = []\n",
    "for image_file in files:\n",
    "    image_set = create_imageset_dict(image_file, \"BayerRG8\")\n",
    "    pipeline_inputs.append({ \"vision_payload\": image_set})\n",
    "\n",
    "len(pipeline_inputs), pipeline_inputs[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the pipeline configuration package locally\n",
    "Take the created _pipeline_inputs_ to be tested as input of the `LocalPipelineRunner`, and run the pipeline with the test data.\n",
    "The `LocalPipelineRunner` module is designed to be used __only__ inside a `with` block.\n",
    "\n",
    "The `run_pipeline` method can be called multiple times but be aware that the internal state of the components is reset between the calls. Use batch input if you want to keep the state between inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from simaticai.testing.pipeline_runner import LocalPipelineRunner\n",
    "\n",
    "image_on_edge_package = Path('../packages/BoardObjectDetection-edge_1.zip')\n",
    "test_dir = Path(\"..\").resolve() / \"test\"\n",
    "\n",
    "pipeline_outputs = []\n",
    "with LocalPipelineRunner(image_on_edge_package, test_dir) as runner:\n",
    "    for i in range(10):\n",
    "        pipeline_output = runner.run_pipeline(pipeline_inputs[randint(0, len(pipeline_inputs) - 1)])\n",
    "        pipeline_outputs.append(pipeline_output)\n",
    "\n",
    "pipeline_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Pipeline step by step\n",
    "\n",
    "In case of any issue occurs, there is an option to test the Pipeline by Components.  \n",
    "Here we use the `run_component` method of `LocalPipelineRunner` instead of `run_pipeline`. In this case there are three Steps in the Pipeline, one for GPURuntimeComponent and two for PythonComponents. This way the inputs and outputs can be investigated independently, or you can execute only one step of the Pipeline, defining only the expected input of that Pipeline step.\n",
    "The main difference between the two type of steps is the Python environment created for them to execute.  \n",
    "While the test environment for a `PythonComponent` is created from the base environment by installing the defined Python packages defined in the requirements.txt of the component, the test environment for a `GPURuntimeComponent` installs only those Python packages, which are required to execute an ONNX model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_on_edge_package = Path('../packages/BoardObjectDetection-edge_1.zip')\n",
    "test_dir = Path(\"..\").resolve() / \"test\"\n",
    "\n",
    "with LocalPipelineRunner(image_on_edge_package, test_dir) as runner:\n",
    "    preprocessing_output  = runner.run_component(\"preprocessing\", pipeline_inputs)\n",
    "\n",
    "    detection_output = runner.run_component(\"detection\", preprocessing_output)\n",
    "    \n",
    "    postprocessing_output = runner.run_component(\"postprocessing\", detection_output)\n",
    "\n",
    "preprocessing_output, detection_output, postprocessing_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the expected outputs can be generated here, you are ready to step one further and give the Pipeline a try on `AI Inference Server`.\n",
    "The main differences on the real device are\n",
    "- underlying CPU, GPU configuration\n",
    "- underlying Operating System\n",
    "- used Python packages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "(Python) Object Detection",
   "language": "python",
   "name": "object_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
