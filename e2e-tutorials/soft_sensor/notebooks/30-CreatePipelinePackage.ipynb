{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "copyright": "Copyright (C) Siemens AG 2021. All Rights Reserved."
   },
   "source": [
    "# Create Pipeline Package for the soft sensor use case\n",
    "\n",
    "In this notebook, the main goal is to create a pipeline with all of the contents that are necessary for the execution of the model on an Industrial Edge device.  \n",
    "In order to put the elements together, this example collects files from the previous notebooks.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a PythonComponent\n",
    "\n",
    "In this step, we create a `PythonComponent` that executes the Python script we created in [notebook 20](./20-CreateInferenceWrapper.ipynb).\\\n",
    "To do so, we need to \n",
    "- collect our file resources\n",
    "- define component inputs and outputs\n",
    "- define the required Python environment\n",
    "\n",
    "The most important information of a PythonComponent is the Python version which the model and Python scripts can work, and it must be set in initialization time.  \n",
    "The further information should be added are the name and a little description on the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simaticai import deployment\n",
    "\n",
    "component = deployment.PythonComponent(\n",
    "    name='valve_controller',  # name of the Pipeline Step\n",
    "    python_version='3.10',    # Python version\n",
    "    desc=\"Predicts the control action based on the sensor payload\"  # Short description of the Pipeline Step\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding file resources\n",
    "\n",
    "As we discussed in [notebook 20](./20-CreateInferenceWrapper.ipynb), the component will predict with the created model and the python code we implemented will execute that prediction.  \n",
    "We created the [entrypoint.py](../src/inference/entrypoint.py) Python file which implements the required `process_input(..)` method.  \n",
    "To create the component, we need to add those file resources and set the entrypoint.\n",
    "\n",
    "Note that the path to the `entrypoint.py` file is `../src/inference/entrypoint.py`.  \n",
    "Similarly, the path to our model is `../models/model.joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "component.add_resources(base_dir='../src/inference', resources='entrypoint.py')\n",
    "component.add_resources(base_dir='../models', resources='model.joblib')\n",
    "component.set_entrypoint('entrypoint.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining component inputs\n",
    "\n",
    "The inputs on the Component must be set to inform AI Inference Server which variables should be gathered from the different data sources and we want to work with them in our entrypoint.  \n",
    "In our example, these are the temperature and valve position values.  \n",
    "In this case we also want to configure that data will be received in batches, so we configure the `inputBatch` on the component to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "component.add_input(\"temperature_A\", \"Double\")\n",
    "component.add_input(\"temperature_B\", \"Double\")\n",
    "component.add_input(\"temperature_C\", \"Double\")\n",
    "component.add_input(\"valve_position_A\", \"Double\")\n",
    "component.add_input(\"valve_position_B\", \"Double\")\n",
    "\n",
    "component.batch.inputBatch = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining component outputs\n",
    "\n",
    "Similarly to the inputs, we also need to inform the AI Inference Server which data will be provided by our component.\\\n",
    "It is our responsibility to provide these data in a dictionary with the keys that reflects on the output variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we defined in the entrypoint.py we return the below dictionary\n",
    "# [...]\n",
    "# return {\"valve_position_A\": valve_position_A, \"valve_position_B\": valve_position_B, \"predicted_phC\": phC_predictions.mean()}\n",
    "\n",
    "component.add_output(\"predicted_phC\", \"Double\")\n",
    "component.add_output(\"valve_control_A\", \"Double\")\n",
    "component.add_output(\"valve_control_B\", \"Double\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Python dependencies\n",
    "\n",
    "The `requirements.txt` should contain only those dependencies which are required while running the model and inference wrapper on AI Inference Server.  \n",
    "Dependencies used during model creation or pipeline building should be excluded.  \n",
    "For this reason we collected all necessary dependencies in the file `runtime_requirements.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component.set_requirements('../src/inference/runtime_requirements.txt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a pipeline from the component\n",
    "\n",
    "Now we can use the component to create a pipeline configuration.  \n",
    "The pipeline requires a list of components - which is a single component in this example - and a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "testinit_package_name"
    ]
   },
   "outputs": [],
   "source": [
    "pipeline = deployment.Pipeline.from_components(\n",
    "    [component], \n",
    "    name='SoftSensorPipeline',\n",
    "    desc='Pipeline to predict the control action based on the sensor payload'\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Pipeline Package\n",
    "\n",
    "This step creates the proper content in the defined target folder `packages` and creates the edge Pipeline Package as a zip file.  \n",
    "The export method first validates the pipeline and raises an error if it finds any problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_package_path = pipeline.export(destination = '../packages')\n",
    "edge_package_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline Package locally\n",
    "\n",
    "We suggest to test the Pipeline Package on your computer before deploying it to an Edge device. It is possible to do so using notebook [40-TestPipelineLocally.ipynb](40-TestPipelineLocally.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (soft_sensor_tutorial)",
   "language": "python",
   "name": "soft_sensor_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
