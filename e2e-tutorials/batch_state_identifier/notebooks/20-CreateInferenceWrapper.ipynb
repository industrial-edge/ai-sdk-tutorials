{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "copyright": "Copyright (C) Siemens AG 2021. All Rights Reserved."
      },
      "source": [
        "# Create the inference wrapper\n",
        "\n",
        "In order to use the trained model, you must write a wrapper script that loads the model and feeds it with the data coming from the configured data source. This notebook helps you to write such a wrapper, and understand how it works.\n",
        "\n",
        "To execute this notebook, you will need the training data and the saved model from the previous notebook [10-CreateModel](10-CreateModel.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model\n",
        "\n",
        "The wrapper script must first load the model into the memory in order to make the prediction as fast as possible.  \n",
        "The filesystem layout (python scripts in `src` folder, model in the `models` folder) is reproduced when running the pipeline, so you can run the same code while experimenting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import joblib\n",
        "\n",
        "sys.path.insert(0, \"../src\")\n",
        "with open(\"../models/bsi-model.joblib\", 'rb') as rpl:\n",
        "    model = joblib.load(rpl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load input data\n",
        "\n",
        "Load the unpacked example training data to test experiment with the implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('../data/processed/example')\n",
        "\n",
        "inputs = []\n",
        "for json_file in data_path.glob('*.json'):\n",
        "    with open(json_file) as f:\n",
        "        json_data = f.read()\n",
        "        inputs.append({\"json_data\": json_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the wrapper\n",
        "\n",
        "The `process_input(data: dict)` method serves as an entrypoint, and will be called for every input batch. It expects the `json_data` field to hold a batch of input data in `JSON` format.\n",
        "\n",
        "It expects the `json_data` to contain a `measurements` field, from which the list of `ph1`, `ph2` and `ph3` values can be extracted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy \n",
        "\n",
        "def process_input(data: dict):\n",
        "    json_data = json.loads(data['json_data'])\n",
        "    measurements = json_data['measurements']\n",
        "    input_data = numpy.array([[[item['ph1'], item['ph2'], item['ph3']] for item in measurements]])\n",
        "    prediction =  model.predict(input_data)\n",
        "    output = {\"prediction\": prediction[0]}\n",
        "    return output\n",
        "\n",
        "# Test it with the example dataset\n",
        "for i, input in enumerate(inputs):\n",
        "    result = process_input(input)\n",
        "    if result is not None: print(i+1, result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Return metrics\n",
        "\n",
        "You can return multiple outputs, and some of those outputs can serve as custom metrics for your running model.\n",
        "\n",
        "When returning such custom metric outputs, the int or float value must be serialized in a specific way, like in the example below.\n",
        "\n",
        "The metrics have to be defined separately when creating a pipeline component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy\n",
        "\n",
        "def process_input(data: dict):\n",
        "    json_data = json.loads(data['json_data'])\n",
        "    measurements = json_data['measurements']\n",
        "    input_data = numpy.array([[[item['ph1'], item['ph2'], item['ph3']] for item in measurements]])\n",
        "    prediction = model.predict(input_data)\n",
        "    output = {\"prediction\": prediction[0]}\n",
        "    # Add metrics\n",
        "    features = model[\"preprocess\"].transform(input_data)[0]\n",
        "    output[\"model_input_min\"]  = metric_output(features[0])\n",
        "    output[\"model_input_max\"]  = metric_output(features[1])\n",
        "    output[\"model_input_mean\"] = metric_output(features[2])\n",
        "    return output\n",
        "\n",
        "def metric_output(v: int or float):\n",
        "    return json.dumps({\"value\": v})\n",
        "\n",
        "# Test it with the example dataset\n",
        "for i, input in enumerate(inputs):\n",
        "    result = process_input(input)\n",
        "    if result is not None: print(i+1, result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the inference wrapper runs the way you desire, you can update the code in [entrypoint.py](../entrypoint.py) and to match yours, and create an edge package in notebook [30-CreatePipelinePackage](30-CreatePipelinePackage.ipynb)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": " Python (batch_state_identifier)",
      "language": "python",
      "name": "batch_state_identifier"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
